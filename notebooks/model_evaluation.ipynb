{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the Hall of Fame Predictions AI!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is soon to be the home of **EVERYTHING** related to sports and data science! For now, we have all you could want and need for every basketball player who has ever played in the NBA or ABA.\n",
    "\n",
    "While we have all the career stats for every player, we also have hall of fame predictions made by our own machine learning algorithm.\n",
    "\n",
    "The type of algorithm running is a **Random Forest Classifier**. A random forest fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting.\n",
    "\n",
    "Here is a visual to help conceptualize what it does."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/random_forest.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Predictions Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build our model we started by scraping the players data from both **https://www.basketball-reference.com** and **https://basketball.realgm.com/nba/players** with our personally built scraper. Afterwards, we seperated all the player data into seperate dataframes based on three categories: current players, retired players who are not in the hall of fame, and retired players who are in the hall of fame. After seperation, the data is cleaned of all NaN values by replacing them with the approriate measure of central tendecy (mean, median, or mode). Then the current players are set aside, as they are the ones who will be receiving predictions, and the hall of fame players data is upsampled so that its number matches that of the retired players not in the hall of fame. Once the samples are even the model can be trained. Below are the statistics of our algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hennybowejr/Documents/hall_of_fame_ai/hofAI/create_mod.py:270: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  stats_num[column] = pd.to_numeric(stats[column], downcast=\"float\")\n",
      "/Users/hennybowejr/Documents/hall_of_fame_ai/hofAI/create_mod.py:272: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  stats_num[\"name\"] = stats[\"name\"].astype(str)\n",
      "/Users/hennybowejr/Documents/hall_of_fame_ai/hofAI/create_mod.py:273: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  stats_num[\"pos\"] = stats[\"pos\"].astype(str)\n",
      "/Users/hennybowejr/Documents/hall_of_fame_ai/hofAI/create_mod.py:278: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hof_num[column] = pd.to_numeric(hof_stats[column], downcast=\"float\")\n",
      "/Users/hennybowejr/Documents/hall_of_fame_ai/hofAI/create_mod.py:280: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hof_num[\"name\"] = hof_stats[\"name\"].astype(str)\n",
      "/Users/hennybowejr/Documents/hall_of_fame_ai/hofAI/create_mod.py:281: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hof_num[\"pos\"] = hof_stats[\"pos\"].astype(str)\n",
      "/Users/hennybowejr/Documents/hall_of_fame_ai/hofAI/create_mod.py:495: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hof_all[column] = pd.to_numeric(hof_all[column], downcast=\"float\")\n",
      "/Users/hennybowejr/Documents/hall_of_fame_ai/hofAI/create_mod.py:497: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hof_all[\"name\"] = hof[\"name\"].astype(str)\n",
      "/Users/hennybowejr/Documents/hall_of_fame_ai/hofAI/create_mod.py:498: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hof_all[\"pos\"] = hof[\"pos\"].astype(str)\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import create_mod as model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       580\n",
      "           1       0.99      1.00      0.99       604\n",
      "\n",
      "    accuracy                           0.99      1184\n",
      "   macro avg       0.99      0.99      0.99      1184\n",
      "weighted avg       0.99      0.99      0.99      1184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model.forest_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The report shows the main classification metrics **precision, recall and f1-score** on a per-class basis. The metrics are calculated by using true and false positives, true and false negatives. Positive and negative in this case are generic names for the predicted classes.\n",
    "\n",
    "### Precision ~ What percent of your predictions were correct?\n",
    "Precision is the ability of a classifier not to label an instance positive that is actually negative. For each class it is defined as the ratio of true positives to the sum of true and false positives.\n",
    "\n",
    "### Recall ~ What percent of the positive cases did you catch?\n",
    "Recall is the ability of a classifier to find all positive instances. For each class it is defined as the ratio of true positives to the sum of true positives and false negatives.\n",
    "\n",
    "### F1_Score ~ What percent of positive predictions were correct?\n",
    "The F1 score is a weighted harmonic mean of precision and recall such that the best score is 1.0 and the worst is 0.0. Generally speaking, F1 scores are lower than accuracy measures as they embed precision and recall into their computation. As a rule of thumb, the weighted average of F1 should be used to compare classifier models, not global accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the model has been built, we create a function that makes use of the current players dataframe and the model's **predict_proba()** function to get the percentage of how likely active players are to be inducted into the hall of fame. This can also be used on retired players who aren't inducted, but should be like say Chris Webber.\n",
    "\n",
    "Moving forward we want to maximum the accuracy and usefulness of our AI predictions, not just for NBA players but players across all sports. Going forward with this particular model, we can make it more accurate by incorporating a player's awards into the model. Right now it only focuses on the players' in game total career stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
